{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python programming: Neural Networks II.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hazrakeruboO/DS-Colabs/blob/main/Python_programming_Neural_Networks_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRSWncnLiehz"
      },
      "source": [
        "<font color=green>To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBF0fg4v8Ky0"
      },
      "source": [
        "##Python programming: Neural Networks II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGl787jB8Wdk"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIqBEYa08EdP"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import a standardization library\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Import an Multi-Layer Perceptron Classifier model estimator from Scikit-Learn's neural_network library\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4myir1B80I9"
      },
      "source": [
        "### Example 1: Breast Cancer Classificaton\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_NgIo4rDnaJ"
      },
      "source": [
        "We are going to use a dataset that we have already worked with before for this example. This intentional beacuse as we understand how neural network works (no pun intended) we will aslo get to understand how it performs with respect to other classification techniques. Let's dive in!!\n",
        "\n",
        "Using the breast cancer dataset, our aim is to classify cancer diagnosis as either Malignant or Benign."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjxsEgvbHLfy"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUWzfMVwHgpQ"
      },
      "source": [
        "# Load data\n",
        "data = pd.read_csv('http://bit.ly/breast_cancer_dataset')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxzr5jMvHwBu"
      },
      "source": [
        "# Drop the column that has NaN values\n",
        "Cancer_data = data.dropna(axis='columns')\n",
        "Cancer_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0tEBqHJIkmS"
      },
      "source": [
        "**Split the data into train and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6XtE5m5IsYt"
      },
      "source": [
        "# Define our features and targets\n",
        " X = Cancer_data.drop(['diagnosis','id'],axis=1) \n",
        " y = np.where(Cancer_data['diagnosis']=='M',0,1)\n",
        "\n",
        " #  Split the data into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) # notice that we are suing the same random state number for the purpose of comparing the performance later\n",
        "\n",
        "# Normalizing the our training data\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Applying the transformation to the data\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYrY1rpEKCAy"
      },
      "source": [
        "**Train the Model**\n",
        "\n",
        "Before we actually code this, Let's look at the various parameters of the MPLClassifier class.\n",
        "When defining MLP, we might consider tuning some parameter because MLP is not meant to work right out of the box so the results might be dissapointing.\n",
        "\n",
        "In the previous session, we saw that for MLP to work we need to define the architecture of the neurons. well, that's just one parameter we can tune. There are a couple other parameters we can play with to make sure that we get the best out of the model.\n",
        "Here are some of the paramters\n",
        "\n",
        "\n",
        "*   **Solver** : This just refers to the gradient descent we want to use in the network. MLP gives us three options;\n",
        "  1.   **SDG** - This is our good old stochastic gradient descent. When using SGD we also need to define the **learning rate**. if we do not define it, it has a default value of 0.001.\n",
        "  2.   **adam** - This is a stochastic gradient based optimizer. It does well when you have a large dataset. You can read more on it in the link provided in the suggested reading section. It is said to have the best perfomance out of the three\n",
        "\n",
        "  1.   **lbfgs** - an optimizer in the family of quasi-Newton methods.\n",
        "\n",
        "\n",
        "*   **Activation**: Here we get to define the type of activation function we want to use in our network. we can use either one of the following;\n",
        "\n",
        "      1.   **logistic** - used for the sigmoid function\n",
        "      2.   **tanh** - used for the hyperbolic tan function\n",
        "      1.   **relu** - used for the recttified linear unit\n",
        "\n",
        "*   **alpha**: In MLP, this is the penalty term. Just like in svm where we denoted our penalty term as c. It helps regulate cases of overfitting.\n",
        "\n",
        "*   **Learning_rate**: This is the learning rate for our SDG. It also has parameters;\n",
        "\n",
        "      1.   **Constant** - refers to a constant learning rate given by learning_rate_init\n",
        "      1.   **invscaling** - it will gradually decrease the learning rate at every step\n",
        "      2.   **adaptive** - this means that the network will keep the learning_rate constant  to the learning_rate _init as long as the training loss keeps decreasing\n",
        "\n",
        "\n",
        "\n",
        "*   **Learning_rate_init**: This is the initial learning rate used. If not declared, the network uses a default value of .001. This parameter is only used when solver is set to either  sdg or adam\n",
        "\n",
        "\n",
        "\n",
        "* **Max_iter**: This indicates the number of iterations. In other words, this is determines the number of epoch.\n",
        "\n",
        "**Note**: Every time you want to increase the accuracy of your model, these are the paramters you will tune \n",
        "\n",
        "Now let's get some code done.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ecENXDbBhO"
      },
      "source": [
        "# Creating our model\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30), activation='logistic', random_state=10, max_iter=500)\n",
        "\n",
        "# fitting the data\n",
        "mlp.fit(X_train,y_train)\n",
        "\n",
        "# Sometimes, depending on the number of iteration convergence might no be reached. When this happens just play around with your max_iteration parameter. To see this in action put your max_iter to the default value of 200 and see what happens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxdcM2DgdPk5"
      },
      "source": [
        "**Prediction and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCSG8rvlOWiH"
      },
      "source": [
        "# Predicting\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "print('-----------------------------------------')\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCnwu8HZfYVM"
      },
      "source": [
        "**Observation/Conclusion**\n",
        "\n",
        "From our evaluation, we can conclude that only 2 tumors were misclassified giving us an accuracy score of 96%. This result is acceptable. \n",
        "\n",
        "Try tuning your parameters to see if you'll get an even better result than we've gotten right now.\n",
        "\n",
        "Lastly, if we were to compare the performance of this model to the performance of the SVM model that we did a while back on the same dataset we can see that Neural Networks have a better performance than the SVM model. This is because using SVM we got an accuracy of 95.6% while we've gotten an accuracy if 96% using Neural Network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRC51TthiHco"
      },
      "source": [
        "## <font color= green>Challenge 1</fonts>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mqpUO44nbKo"
      },
      "source": [
        "# Lower back pain can be caused by a variety of problems with any parts of the complex, interconnected network of spinal muscles, nerves, bones, discs or tendons in the lumbar spine.\n",
        "# An irritation or problem with any of these structures can cause lower back pain and/or pain that radiates or is referred to other parts of the body. \n",
        "# Many lower back problems also cause back muscle spasms, which don't sound like much but can cause severe pain and disability.\n",
        "# While lower back pain is extremely common, the symptoms and severity of lower back pain vary greatly. \n",
        "# A simple lower back muscle strain might be excruciating enough to necessitate an emergency room visit, while a degenerating disc might cause only mild, intermittent discomfort\n",
        "# Use the following dataset to classify a persons spine as either normal or abnormal\n",
        "# Dataset Url -------> http://bit.ly/spine_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tciVdT03v-uj"
      },
      "source": [
        "## <font color= green>Challenge 2</fonts>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGC2Oy5av6Vh"
      },
      "source": [
        "# You are given a dataset that hava various traits of zoo animals and you are required to classify the animals into 7 classes: Mammal, Bird, Reptile, Fish, Amphibian, Bug and Invertebrate\n",
        "# Use neural networks to achive this objective\n",
        "# Dataset1 Url ----> http://bit.ly/zoo_data\n",
        "# Dataset2 url-------http://bit.ly/zoo_class"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}