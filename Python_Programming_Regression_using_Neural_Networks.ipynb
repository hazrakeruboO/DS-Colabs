{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Programming: Regression using Neural Networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hazrakeruboO/DS-Colabs/blob/main/Python_Programming_Regression_using_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LKIYSQ2hbHV"
      },
      "source": [
        "<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjgJDCQIiAcp"
      },
      "source": [
        "## Python Programming:Regression using Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuHTc-CViuOV"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQFuwqKVhX4e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Import an Multi-Layer Perceptron Regressor model estimator from Scikit-Learn's neural_network library\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tJq9aV9lRNa"
      },
      "source": [
        "### Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ3puK-qld_Z"
      },
      "source": [
        "In this example we are going to use a dataset that we've have worked with before for the purpose of comparing the perfomance of the model.\n",
        "\n",
        "Remember the example we looked at while doing linear regression, we'll tackle the same problem but now using neural networks. \n",
        "\n",
        "To refresh your mind, we were trying to predict a students chance of getting into grad school based on some tests.\n",
        "\n",
        "Let's dive in!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUeP6WYjqIo_"
      },
      "source": [
        "**Loading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-aVVtb2qTVX"
      },
      "source": [
        "#load the data\n",
        "data = pd.read_csv('http://bit.ly/uni_admission')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LTbYj5EbPAf"
      },
      "source": [
        "#### Using 1 feauture\n",
        "First, we'll use only 1 feature and see how it performs then, we'll go ahead and increase the number of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujGJBMXiuswP"
      },
      "source": [
        "# First, we'll use the GRE test scores to predict\n",
        "\n",
        "X = data['GRE'].as_matrix()\n",
        "y = data['admit_chance']\n",
        "\n",
        "\n",
        "data.plot(x='GRE', y='admit_chance', style='o')\n",
        "plt.title('GRE Score VS Chance of admission')\n",
        "plt.xlabel('GRE score')\n",
        "plt.ylabel('chance of admission')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX6RP99pfKqW"
      },
      "source": [
        "# Split the dataset into train and test set\n",
        "X_train, X_test, y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=20)\n",
        "\n",
        "# Just like we did in the classifier, we need to normalize our data\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler\n",
        "scaler.fit(X_train.reshape(-1,1)) # Here, we are using reshape because normally the scaler expects a 2D array but we have given it a 1D array instead. So we reshape the array and tell it that we have 1 array and an unknown number rows,\n",
        "\n",
        "# Applying the transformation to the data\n",
        "X_train = scaler.transform(X_train.reshape(-1,1))\n",
        "\n",
        "X_test = scaler.transform(X_test.reshape(-1,1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTheOCQkkpVM"
      },
      "source": [
        "**Training the Model**\n",
        "\n",
        "Similar to the model classifier, the regressor also using the same parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq5ppa__knf9"
      },
      "source": [
        "# Instatiating the model\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(50,50), solver='sgd', activation='identity') #Since we are doing a linear regression then we don't really need the activation function so we use activation as identity\n",
        "\n",
        "# fitting the model\n",
        "mlp.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHOKRRhDng4E"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ8ZfwI9nko9"
      },
      "source": [
        "# Predicting\n",
        "y_pred = mlp.predict(X_test.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYKI4NzwnIeH"
      },
      "source": [
        "**Visualization**\n",
        "\n",
        "Since we are using only 1 feature, we can easily visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqfUtXoSnWcr"
      },
      "source": [
        "plt.scatter(X_test, y_test, color='black')\n",
        "plt.plot(X_test, y_pred, color='red', linewidth=2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUqRHhjshuI"
      },
      "source": [
        "**Evaluaton**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE1fXnuUs0Ew"
      },
      "source": [
        "# Our first metric is MAE - Mean absolute error\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "\n",
        "# We can also use MSE - Mean squared error\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
        "\n",
        "# Finally, the most popular metric: RMSE - Root mean squared error\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COm3Xos1yrHP"
      },
      "source": [
        "#### Using Muiltiple feautures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8VlnHQ4y0Vo"
      },
      "source": [
        "# Seperating our target from our features\n",
        " X = data[['GRE','TOEFL']].values\n",
        " y = data['admit_chance']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxdPKLebz5nT"
      },
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train,y_test = train_test_split(X,y, test_size=0.2, random_state = 20)\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting the scaler\n",
        "scaler.fit(X_train )\n",
        "\n",
        "# Applying the transformation to the data\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BHswJCZ1mdR"
      },
      "source": [
        "**Model Training**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFNt-zVj1v9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9e2d8b3e-af28-42eb-a773-9c8a24e27efa"
      },
      "source": [
        "mlp = MLPRegressor(hidden_layer_sizes=(50,50), solver='sgd', activation='identity')\n",
        "\n",
        "# Fitting the model\n",
        "mlp.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "             hidden_layer_sizes=(50, 50), learning_rate='constant',\n",
              "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "             random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
              "             validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NuxY-SA2rW7"
      },
      "source": [
        "**Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dvi6Bug2dgi"
      },
      "source": [
        "# Making predictions\n",
        "y_pred = mlp.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U2Z4MEf2UEw"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jER6omK_2ZfP"
      },
      "source": [
        "# Our first metric is MAE - Mean absolute error\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "\n",
        "# We can also use MSE - Mean squared error\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
        "\n",
        "# Finally, the most popular metric: RMSE - Root mean squared error\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH039XGA5dZ-"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "We can conclude that there is a slight improvement when using multiple features. This is refected by the decrease in the RMSE.\n",
        "\n",
        "Remember, you can always tune your parameters for better results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATRmyF3s576y"
      },
      "source": [
        "### <font color='green'>Challenge</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChR2MHWF6Qr_"
      },
      "source": [
        "# Use NN to predict a persons salary based on their experience\n",
        "# Dataset url ------> http://bit.ly/salary_dataset"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}