{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hazrakeruboO/DS-Colabs/blob/main/RLab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5f0771f6980ffb5127eb2de4d2546a51",
          "grade": false,
          "grade_id": "cell-3bdbef72d377d7c5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "sKRwBVhdmOpE"
      },
      "source": [
        "## RLab 3\n",
        "\n",
        "In this RLab assignment, we will use the k-nearest neighbors (knn) algorithm to classify and predict new observations with their proximity to k most-similar observations from training data. In the case of categorical target variable, we use classification method by using the majority rule in K- nearest neighbors.  If, on the other hand, we have a numerical target variable, then it is considered as a regression problem and we use the mean value in the K- nearest neighbors.  When it comes to distance measurement, the most commonly used distance measures are Euclidean, Manhattan, and Minkowski distances. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7b93fac47ba9563f632d31a780486f2b",
          "grade": false,
          "grade_id": "cell-bf9b3722239fba79",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "TeFE7KL6mOpc"
      },
      "source": [
        "##  Credit Data \n",
        "\n",
        "\n",
        "We will use the credit data from RLab 2 to identify whether a customer is risky or not in terms of repaying the loan. But, this time, instead of logistic regression, we will classify customers based on the knn algorithm and only use 4 predictors from the list.  The dataset is in csv format, we read the data with read.csv command in R.   \n",
        "\n",
        "The Credit dataset includes the following variables:\n",
        "- **creditability**:  Credit risk, Good (1), Bad (0)  (This is our target variable.)\n",
        "- **payment_status**: Payment Status of Previous Credit. Unknown (0), Some Problems (1), Paid Up (2), No Problems (in this bank) (3),  No Problems (in all banks) (4)\n",
        "- **credit_amount**: current amount of credit from other accounts\n",
        "- **sex_marital**: Sex and marital status: Male Divorced/Single (1), Male Married/Widowed (2), Female  Married/Widowed  (3), Female Divorced/Single (4)\n",
        "- **age**: Age in years\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "68ec13fd51239a643fd93145e7a69ede",
          "grade": false,
          "grade_id": "cell-6b0c67293e9c4b10",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "6P_EyZwfmOpg",
        "outputId": "469846c9-e01b-4405-b6d5-6a9731ae9a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in system(\"timedatectl\", intern = TRUE):\n",
            "“running command 'timedatectl' had status 1”\n",
            "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
            "\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
            "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.6     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
            "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
            "\n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in library(caret): there is no package called ‘caret’\nTraceback:\n",
            "1. library(caret)"
          ]
        }
      ],
      "source": [
        "# call the libraries we will use in the lab assignment\n",
        "library(tidyverse)\n",
        "library(caret)\n",
        "library(dplyr)\n",
        "library(testthat)\n",
        "library(ggplot2)\n",
        "library(recipes)\n",
        "library(class)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cf2ffb860055cb49e3bcd9fb5f0f3437",
          "grade": false,
          "grade_id": "cell-b8364c0d94eba404",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "g32jorGamOpo",
        "outputId": "413df166-2684-4ea7-fefb-f919b5118e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in file(file, \"rt\"):\n",
            "“cannot open file 'credit.csv': No such file or directory”\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
            "1. read.csv(\"credit.csv\", header = TRUE, sep = \",\")",
            "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
            "3. file(file, \"rt\")"
          ]
        }
      ],
      "source": [
        "# import the credit.csv data and name it as  creditdata in R. Data has the column names in the first row, so set header=TRUE\n",
        "creditdata<-read.csv(\"credit.csv\", header = TRUE, sep = \",\")\n",
        "# as can be seen with str(creditdata), some factor variables are coded as integer. \n",
        "\n",
        "# keep only certain variables\n",
        "creditdata<-subset(creditdata, select=c('creditability','payment_status','credit_amount','sex_marital', 'age'))\n",
        "\n",
        "\n",
        "\n",
        "# names of the columns that will need to be entered as factor data\n",
        "columns<-c('creditability','payment_status','sex_marital')\n",
        "# use the lapply function to selected columns to declare as factor\n",
        "creditdata[,columns]<-lapply(creditdata[,columns], factor)\n",
        "\n",
        "\n",
        "\n",
        "# check the data structure\n",
        "str(creditdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c50356750ccebec1e330890ffa36b4bd",
          "grade": false,
          "grade_id": "cell-2b81addb146253aa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VuE-AyxbmOpq"
      },
      "outputs": [],
      "source": [
        "# look at the boxplot of numerical features stratified by creditability\n",
        "par(mfrow=c(1,3))\n",
        "plot ( credit_amount     ~ creditability     , data=creditdata)\n",
        "plot ( age               ~ creditability     , data=creditdata)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6cb8299e4dc403d9d6dce806313dd6e7",
          "grade": false,
          "grade_id": "cell-485040af67e0aad9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wliPeloZmOpt"
      },
      "outputs": [],
      "source": [
        "# look at the scatter plot of numerical variables\n",
        "ggplot(creditdata, aes(x = age, y = credit_amount, color = creditability)) +\n",
        "  geom_point() +\n",
        "  labs(x = \"age\", y = \"credit_amount\", color = \"creditability  \") \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b5d88a6d745ae390651eff2701962c7d",
          "grade": false,
          "grade_id": "cell-600b9dd1a6430d28",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "l8gV8CtZmOpu"
      },
      "source": [
        "## Data pre-processing\n",
        "Before conducting knn analysis, we will need to prepare our data: \n",
        "- First, we will split data into test and training sets.\n",
        "- Then, in the second step, we will do  centering and scaling.  For numerical data,  we will need to **center** and **scale** data to prevent differences in unit of measurements to dominate the distance measurement.  \n",
        "- For categorical features, we will conduct **one-hot encoding** such that there will be one dummy variable for each group of a categorical variable. \n",
        "\n",
        "In this lab assignment, we will use  **recipe** function in **recipes** package to pre process the data. **step_center** and **step_scale** functions are used to scale the data and **step_dummy** function to conduct **one-hot encoding**, shown in the next code chunk.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1736e76b0809aef93b992aeaf9e78fc7",
          "grade": false,
          "grade_id": "cell-33fcfd0595465f11",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qvzgVLFvmOpx"
      },
      "outputs": [],
      "source": [
        "# Step 1: data splitting with caret package. Hold 30% for testing. \n",
        "\n",
        "set.seed(4230) \n",
        "row_index <- createDataPartition(creditdata$creditability, p = 0.7,\n",
        "list = FALSE)\n",
        "train_set <- creditdata[row_index, ]  # name training set\n",
        "test_set <- creditdata[-row_index, ]   # name the test set\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# steps 2 and 3\n",
        "# some cleaning with recipe function. do the pre processing on the train_set\n",
        " \n",
        "features_train <- recipe(creditability  ~ ., data = creditdata) %>%\n",
        "  step_center(all_numeric(), -all_outcomes()) %>%\n",
        "  step_scale(all_numeric(), -all_outcomes())%>%\n",
        "step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%\n",
        "prep(training = train_set, retain = TRUE) %>%\n",
        "juice() %>%\n",
        "  select(-creditability)\n",
        "\n",
        "\n",
        "# some cleaning with recipe function. do the pre processing on the test_set\n",
        "features_test <- recipe(creditability  ~ ., data = creditdata) %>%\n",
        "  step_center(all_numeric(), -all_outcomes()) %>%\n",
        "  step_scale(all_numeric(), -all_outcomes())%>%\n",
        "step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%\n",
        "prep(training = test_set, retain = TRUE) %>%\n",
        "juice() %>%\n",
        "  select(-creditability)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In the original data, we had two numerical and two categorical variables:\n",
        "#payment_status with 5 classes and sex_marital with 4 classes\n",
        "#With one-hot encoding, payment_status variable is  splitted into five dummies\n",
        "\n",
        "# And sex_marital   variable is splitted into four dummy variables \n",
        "# In total, we ended up with 11 features\n",
        "# 'credit_amount''age''payment_status_X0''payment_status_X1''payment_status_X2''payment_status_X3''payment_status_X4''sex_marital_X1''sex_marital_X2''sex_marital_X3''sex_marital_X4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8a2e0ed2eec31d0946ebeb717f62ef97",
          "grade": false,
          "grade_id": "cell-8863079730092611",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "hQ9oYrDamOp0"
      },
      "outputs": [],
      "source": [
        "# check the dimension of the features \n",
        "# With one hot encoding, instead of four , we now have eleven predictors\n",
        "print(dim(features_train))\n",
        "\n",
        "# check the summary statistics of features\n",
        "print(summary(features_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3ba29f388fd9c47a868682beb270ef85",
          "grade": false,
          "grade_id": "cell-e2048a12c406e115",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "0G0JM26MmOp2"
      },
      "source": [
        "## knn approach\n",
        "Knn approach is not good at handling missing values.  Luckily, there is no missing value in our dataset and it can be checked with the following line of code: \n",
        "**sapply(creditdata, function(x) sum(is.na(x)))**\n",
        "\n",
        "We will use **knn** function in **class** package to get the label predictions. \n",
        "\n",
        "\n",
        "First, for illustration purposes, we will select one data point from the test set, calculate the distance to each observation in the training data set and look at the closest observations and their corresponding labels. Distance is a measure of dissimilarity, the closer the distance between two observations, the higher the similarity. This is just a practice to help you understand the algorithm behind knn. \n",
        "\n",
        "First, we will use **dist()** function in R and calculate the Manhattan distance between the first observation in the test set and each observation in the training set. Since we need all numerical variables to be scaled and categorical variables to be hot-encoding, we will use  **features_train** and **features_test** for distance measurement. \n",
        "\n",
        "\n",
        " \n",
        " We take the first observation in test data (we name it as test1 below) and calculate the pairwise distances for each observation in the train set and later collect them in a data frame along with the train data labels and call it **collect**.\n",
        " \n",
        " In  **collect**, the first column **train_label** shows the data label in train data set. The second column **distance** shows the Manhattan distance from the first observation in the test data set and each observation in the train dataset.  \n",
        " \n",
        "       \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c022665f2105233340cb7835d671abcb",
          "grade": false,
          "grade_id": "cell-fcefab548128be3c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tG-BMVdwmOp4"
      },
      "outputs": [],
      "source": [
        "test1<-features_test[1,]  # this is the first observation in test data\n",
        "\n",
        "combine <- rbind(test1,features_train)  # stack test1 and train data feaures, test1 being the first row\n",
        "\n",
        "distanceALL<-as.matrix(dist(combine, method = \"manhattan\"))  # calculate distance from each row in combine against all other rows and save it as a matrix\n",
        "collect<-cbind(as.data.frame(train_set$creditability),distanceALL[2:701,1]) # combine train_set labels with the distance measure\n",
        "names<-c('train_label','distance')\n",
        "names(collect) <-names\n",
        "head(collect)  # list the first few observations in collect\n",
        "\n",
        "collect<-as.data.frame(collect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b7a56ac227ffc0f5e6c44dff8a363f2e",
          "grade": false,
          "grade_id": "cell-bd9700dd77772f48",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XOLOGDMcmOp5"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Sort **collect** based on **distance** in ascending order (from lowest to highest) and only show the first 9 rows and call it **Nine_neighbors**. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4c9738399286931f863a622a8ae2e048",
          "grade": false,
          "grade_id": "cell-f5ab77d33b04b902",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "L5AneTQ2mOp6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Exercise #1:  List the Nine_neighbors\n",
        "\n",
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ecd9cb4dc45aecf40ccb70973b508498",
          "grade": true,
          "grade_id": "cell-e10615c8c0057321",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "sdka8KnumOp7"
      },
      "outputs": [],
      "source": [
        "# Test your code in here\n",
        "### BEGIN HIDDEN TEST\n",
        "\n",
        "\n",
        "test_that(\"Check distance measures\", {\n",
        "    expect_equal( min(Nine_neighbors$distance),0.0574817558633449)})\n",
        "\n",
        "test_that(\"Check distance measures\", {\n",
        "    expect_equal( max(Nine_neighbors$distance),0.29251146576787)})\n",
        "\n",
        "\n",
        "test_that(\"Check distance measures\", {\n",
        "    expect_equal( mean(Nine_neighbors$distance),0.185849316164428)})\n",
        "        \n",
        "print(\"Passed!\")\n",
        "\n",
        "### END HIDDEN TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "739518429be3345e404c016b96937794",
          "grade": false,
          "grade_id": "cell-de5a8ce341464977",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qR-rVi0lmOp9"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "Use **knn** function in **class** package and predict labels in the test data with knn when k=5. Use **set.seed(4230)** and name the predicted  test data labels  as **knn_five**. (**knn_five** is a vector of length 300)   \n",
        "\n",
        "Please note than knn() function in the class package requires predictors and labels to be entered separately. More specifically, predictors need to be a matrix and the label to be a vector only. Hence,  you need to feed the knn() function with  **features_train** and **train_set$creditability** where the former is in matrix format and the latter is a vector. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9f09c4f7dfc3556e9db6fc00803bcd35",
          "grade": false,
          "grade_id": "cell-4028e81e7a08ea68",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HD3v8HtHmOp-"
      },
      "outputs": [],
      "source": [
        "class_error = function(actual, predicted) {\n",
        "  mean(actual != predicted)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "352726145648c155ed3bbd2fca98ecd4",
          "grade": false,
          "grade_id": "cell-7e996ac7cba4fbef",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3rGeGYaNmOp_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Exercise #2: knn results when k=5\n",
        "\n",
        "# your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a9da331e953c877d2d02abd482cf8cfc",
          "grade": true,
          "grade_id": "cell-492bd728ea73f9f2",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BX9GghHRmOqA"
      },
      "outputs": [],
      "source": [
        "# Test your code in here\n",
        "### BEGIN HIDDEN TEST\n",
        "class_error = function(actual, predicted) {\n",
        "  mean(actual != predicted)\n",
        "}\n",
        "\n",
        "test_that(\"Check the classification error\", {\n",
        "    expect_equal( class_error(test_set$creditability,knn_five),0.353333333333333)})\n",
        "        \n",
        "print(\"Passed!\")\n",
        "\n",
        "### END HIDDEN TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b6ca1742499b18b88aef9b87667d4a78",
          "grade": false,
          "grade_id": "cell-02e1517312287554",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zak6Q2--mOqB"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "Use **knn** function in **class** package and predict labels in the test data with knn when k=10. Use **set.seed(4230)** and name the predicted  test data labels  as **knn_ten**. (**knn_ten** is a vector of length 300)   \n",
        "\n",
        "Please note than knn() function in class package requires predictors and labels to be entered separately. More specifically, predictors need to be a matrix and the label to be a vector only. Hence,  you need to feed the knn() function with  **features_train** and **train_set$creditability** where the former is in matrix format and the latter is a vector. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b59837e8827044e31983c6b0898ba15d",
          "grade": false,
          "grade_id": "cell-b4cb350ba367eb2e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "BV-qQY2MmOqD"
      },
      "outputs": [],
      "source": [
        "# Exercise #3: knn results when k=10\n",
        "\n",
        "# your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "664ac6f6b2312234a2c18e0eaf1e335e",
          "grade": true,
          "grade_id": "cell-b4b96cbe6b34071e",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2k5uE6n8mOqE"
      },
      "outputs": [],
      "source": [
        "# Test your code in here\n",
        "### BEGIN HIDDEN TEST\n",
        "class_error = function(actual, predicted) {\n",
        "  mean(actual != predicted)\n",
        "}\n",
        "\n",
        "test_that(\"Check the classification error\", {\n",
        "    expect_equal( class_error(test_set$creditability,knn_ten),0.323333333333333)})\n",
        "        \n",
        "print(\"Passed!\")\n",
        "\n",
        "### END HIDDEN TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1f85483a915b754e42058ca03e78a7fa",
          "grade": false,
          "grade_id": "cell-e3c8d2ce9046d6fa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "jc8_-ytsmOqF"
      },
      "source": [
        "## Exercise 4:  Performance Measure\n",
        "This time, we will take the predicted results based on **knn_ten** above and by using the confusion matrix, we will calculate several misclassification measures. Note that if someone has good credit,  creditability=1, we define it as a positive event. For instance, True Negative (TN) refers to cases where the true label (creditability) is 0, and our model predicts it as 0. Likewise, False Negative (FN) refers to cases where true label was 1 (good credit), but the model predicted to be 0. \n",
        "\n",
        "**measure** is a 4X2 matrix: the first column stores the performance measure names. Your task is to calculate each performance measure and enter your findings in the second column of measure.  **IMPORTANT:**  You need to enter your findings with two decimal points for the test to pass.  \n",
        "- For instance, if your performance measure is 0.27777777777777,  enter as 0.28.\n",
        "- For instance, if your performance measure is 0.4839123412342,  enter as 0.48.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "900523b78be038036b16e65eb4e7134b",
          "grade": false,
          "grade_id": "cell-d06d507a909d926a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WAo8538qmOqG"
      },
      "outputs": [],
      "source": [
        "# create a table to record model performance \n",
        "nam<-c(\"Accuracy\", \"Precision\", \"Sensitivity\",\"Specificity\", \" \",\" \",\" \",\" \")  # name the rows\n",
        "measure<-matrix(nam, nrow=4, ncol=2, byrow=FALSE)     # create a 4X2 matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c667fed06e4f0995041de67f65ce7f3f",
          "grade": false,
          "grade_id": "cell-a73d16fb1d63dcd8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cjxU60LUmOqH"
      },
      "outputs": [],
      "source": [
        "# Exercise #4: Performance measure\n",
        "\n",
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "62a06a73355d9f078b7b97807f8397a7",
          "grade": true,
          "grade_id": "cell-86a4752ae988ee2d",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XJmbZXE8mOqI"
      },
      "outputs": [],
      "source": [
        "# Test your code in here\n",
        "### BEGIN HIDDEN TEST\n",
        "\n",
        "test_that(\"Check the results\", {\n",
        "    expect_equal(as.numeric(measure[1,2])*as.numeric(measure[2,2])*as.numeric(measure[3,2]) ,0.42194\n",
        ")})\n",
        "\n",
        "\n",
        "test_that(\"Check the results\", {\n",
        "    expect_equal(as.numeric(measure[3,2])*as.numeric(measure[4,2]) ,0.238\n",
        "\n",
        ")})\n",
        "\n",
        "        \n",
        "print(\"Passed!\")\n",
        "\n",
        "\n",
        "\n",
        "### END HIDDEN TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b1512f49ec51b68f2933c007b96b7b14",
          "grade": false,
          "grade_id": "cell-b4250467ceb7998d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DZRMxkECmOqJ"
      },
      "source": [
        "## Parameter Tuning\n",
        "\n",
        "In knn, k is the only parameter we need to tune to find the optimal k. Next, we try k values from 1 to 50, and calculate the classification error for each k and save them as **k_class_error**. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b5df5cfd219432b97042660bdb9e3806",
          "grade": false,
          "grade_id": "cell-5d2580da96210f18",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9iavTj8DmOqJ"
      },
      "outputs": [],
      "source": [
        "set.seed(4230)\n",
        "k_values = 1:50\n",
        "k_class_error = seq(0,0,length.out=length(k_values))\n",
        "\n",
        "for (i in seq_along(k_values)) {\n",
        "  predicted_labels =  knn(train = features_train, \n",
        "         test  = features_test, \n",
        "         cl    = train_set$creditability, \n",
        "         k     =k_values[i] )\n",
        "  k_class_error[i] = class_error(test_set$creditability, predicted_labels)\n",
        "}\n",
        "\n",
        "print(k_class_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7556343581f45477c44f81420d497b89",
          "grade": false,
          "grade_id": "cell-efefebd93f9e6d0e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZvAYyNykmOqK"
      },
      "source": [
        "## Exercise 5:\n",
        " Write a function to find the optimal k  (the k value which minimizes the classification error) and call it **optimal_k**.  In other words, at which value of **k** does the **k_class_error** take the minimum value?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8f044c4fa4ac1dd7167961aa6d0f6325",
          "grade": false,
          "grade_id": "cell-c849d747d413540a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "0nq2YNgwmOqL"
      },
      "outputs": [],
      "source": [
        "# Exercise #5: find the optimal k\n",
        "\n",
        "# your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "699ef4499d393984803e478b93a7f198",
          "grade": true,
          "grade_id": "cell-ace0ead680423117",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IuzUOt8_mOqL"
      },
      "outputs": [],
      "source": [
        "# Test your code in here\n",
        "### BEGIN HIDDEN TEST\n",
        "\n",
        "test_that(\"Check the optimal k\", {\n",
        "    expect_equal( optimal_k/4,8)})\n",
        "        \n",
        "print(\"Passed!\")\n",
        "\n",
        "\n",
        "### END HIDDEN TEST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6bfb08e8f87b3f4717903c2e1537b624",
          "grade": false,
          "grade_id": "cell-8c7ab42692d44aeb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FGofDhEbmOqM"
      },
      "source": [
        "## Cross validation\n",
        "A better approach to find the optimal k is cross-validation.  One can use caret package to conduct k-fold cross validation very easily. Since the Coursera platform does not support certain packages in the Lab Manager, we skipped the cross-validation part. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.3"
    },
    "colab": {
      "name": "RLab3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}