{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Python Programming: Bayes Theorem",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hazrakeruboO/DS-Colabs/blob/main/Copy_of_Python_Programming_Bayes_Theorem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgp1DV4UuWzW"
      },
      "source": [
        "<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8flRWHtSHki3"
      },
      "source": [
        "# Python Programming: Bayes Theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96w9G0XWJrC3"
      },
      "source": [
        "The Bayes Theorem is applicable in machine learning where we get to use a Bayes classifier inorder to make a prediction. In this session, we will learn how to apply this classifer to a few machine learning problems even though later during Core we will spent time exhaustively on working on such problems. While working, we should note that the bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. \n",
        "\n",
        "For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this fruit is an apple and that is why it is known as ‘Naive’.\n",
        "\n",
        "Such classifiers, Naive Bayes classifiers, are a collection of classification algorithms based on Bayes’ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhgc8dlkL_UT"
      },
      "source": [
        "## Example "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lBLmRc5HgqE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "1ebe285c-2b98-4dd9-9a21-cebca0e14576"
      },
      "source": [
        "# Example 1\n",
        "import pandas as pd\n",
        "# ---\n",
        "# Let's see an overview on how this classifier works, which suitable applications it has, \n",
        "# and how to use it in just a few lines of Python and the Scikit-Learn library.\n",
        "# ---\n",
        "# Question: Build a very simple SPAM detector for SMS messages given the following dataset; \n",
        "# ---\n",
        "# Dataset source = https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
        "\n",
        "df = pd.read_csv('/content/SMSSpamCollection.txt',error_bad_lines=False)\n",
        "df.head(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "b'Skipping line 12: expected 2 fields, saw 4\\nSkipping line 42: expected 2 fields, saw 3\\nSkipping line 57: expected 2 fields, saw 4\\nSkipping line 66: expected 2 fields, saw 3\\nSkipping line 68: expected 2 fields, saw 3\\nSkipping line 86: expected 2 fields, saw 3\\nSkipping line 90: expected 2 fields, saw 3\\nSkipping line 96: expected 2 fields, saw 3\\nSkipping line 116: expected 2 fields, saw 4\\nSkipping line 128: expected 2 fields, saw 4\\nSkipping line 148: expected 2 fields, saw 3\\nSkipping line 156: expected 2 fields, saw 11\\nSkipping line 175: expected 2 fields, saw 3\\nSkipping line 201: expected 2 fields, saw 3\\nSkipping line 228: expected 2 fields, saw 3\\nSkipping line 240: expected 2 fields, saw 3\\nSkipping line 244: expected 2 fields, saw 3\\nSkipping line 253: expected 2 fields, saw 3\\nSkipping line 283: expected 2 fields, saw 4\\nSkipping line 290: expected 2 fields, saw 5\\nSkipping line 291: expected 2 fields, saw 3\\nSkipping line 303: expected 2 fields, saw 3\\nSkipping line 310: expected 2 fields, saw 6\\nSkipping line 313: expected 2 fields, saw 3\\nSkipping line 318: expected 2 fields, saw 3\\nSkipping line 329: expected 2 fields, saw 3\\nSkipping line 354: expected 2 fields, saw 4\\nSkipping line 357: expected 2 fields, saw 3\\nSkipping line 360: expected 2 fields, saw 4\\nSkipping line 400: expected 2 fields, saw 6\\nSkipping line 414: expected 2 fields, saw 3\\nSkipping line 420: expected 2 fields, saw 3\\nSkipping line 447: expected 2 fields, saw 4\\nSkipping line 448: expected 2 fields, saw 6\\nSkipping line 460: expected 2 fields, saw 4\\nSkipping line 483: expected 2 fields, saw 3\\nSkipping line 490: expected 2 fields, saw 3\\nSkipping line 493: expected 2 fields, saw 4\\nSkipping line 520: expected 2 fields, saw 3\\nSkipping line 537: expected 2 fields, saw 3\\nSkipping line 552: expected 2 fields, saw 4\\nSkipping line 561: expected 2 fields, saw 3\\nSkipping line 569: expected 2 fields, saw 3\\nSkipping line 577: expected 2 fields, saw 4\\nSkipping line 625: expected 2 fields, saw 3\\nSkipping line 636: expected 2 fields, saw 3\\nSkipping line 643: expected 2 fields, saw 3\\nSkipping line 651: expected 2 fields, saw 5\\nSkipping line 662: expected 2 fields, saw 5\\nSkipping line 693: expected 2 fields, saw 4\\nSkipping line 705: expected 2 fields, saw 3\\nSkipping line 726: expected 2 fields, saw 4\\nSkipping line 759: expected 2 fields, saw 4\\nSkipping line 768: expected 2 fields, saw 4\\nSkipping line 790: expected 2 fields, saw 4\\nSkipping line 802: expected 2 fields, saw 3\\nSkipping line 816: expected 2 fields, saw 3\\nSkipping line 824: expected 2 fields, saw 3\\nSkipping line 834: expected 2 fields, saw 4\\nSkipping line 850: expected 2 fields, saw 3\\nSkipping line 864: expected 2 fields, saw 3\\nSkipping line 877: expected 2 fields, saw 7\\nSkipping line 883: expected 2 fields, saw 5\\nSkipping line 900: expected 2 fields, saw 3\\nSkipping line 901: expected 2 fields, saw 3\\nSkipping line 908: expected 2 fields, saw 4\\nSkipping line 919: expected 2 fields, saw 3\\nSkipping line 938: expected 2 fields, saw 4\\nSkipping line 946: expected 2 fields, saw 3\\nSkipping line 958: expected 2 fields, saw 5\\nSkipping line 984: expected 2 fields, saw 4\\nSkipping line 989: expected 2 fields, saw 3\\nSkipping line 990: expected 2 fields, saw 7\\nSkipping line 1010: expected 2 fields, saw 5\\nSkipping line 1011: expected 2 fields, saw 3\\nSkipping line 1022: expected 2 fields, saw 3\\nSkipping line 1039: expected 2 fields, saw 4\\nSkipping line 1040: expected 2 fields, saw 5\\nSkipping line 1087: expected 2 fields, saw 3\\nSkipping line 1103: expected 2 fields, saw 3\\nSkipping line 1119: expected 2 fields, saw 3\\nSkipping line 1121: expected 2 fields, saw 3\\nSkipping line 1165: expected 2 fields, saw 3\\nSkipping line 1178: expected 2 fields, saw 3\\nSkipping line 1208: expected 2 fields, saw 4\\nSkipping line 1215: expected 2 fields, saw 4\\nSkipping line 1217: expected 2 fields, saw 3\\nSkipping line 1250: expected 2 fields, saw 3\\nSkipping line 1251: expected 2 fields, saw 3\\nSkipping line 1309: expected 2 fields, saw 3\\nSkipping line 1317: expected 2 fields, saw 5\\nSkipping line 1328: expected 2 fields, saw 3\\nSkipping line 1369: expected 2 fields, saw 3\\nSkipping line 1375: expected 2 fields, saw 4\\nSkipping line 1386: expected 2 fields, saw 3\\nSkipping line 1391: expected 2 fields, saw 3\\nSkipping line 1392: expected 2 fields, saw 3\\nSkipping line 1394: expected 2 fields, saw 3\\nSkipping line 1414: expected 2 fields, saw 3\\nSkipping line 1430: expected 2 fields, saw 3\\nSkipping line 1476: expected 2 fields, saw 6\\nSkipping line 1509: expected 2 fields, saw 3\\nSkipping line 1514: expected 2 fields, saw 4\\nSkipping line 1528: expected 2 fields, saw 3\\nSkipping line 1545: expected 2 fields, saw 4\\nSkipping line 1547: expected 2 fields, saw 3\\nSkipping line 1584: expected 2 fields, saw 3\\nSkipping line 1585: expected 2 fields, saw 3\\nSkipping line 1589: expected 2 fields, saw 4\\nSkipping line 1606: expected 2 fields, saw 4\\nSkipping line 1618: expected 2 fields, saw 3\\nSkipping line 1622: expected 2 fields, saw 4\\nSkipping line 1625: expected 2 fields, saw 3\\nSkipping line 1629: expected 2 fields, saw 3\\nSkipping line 1636: expected 2 fields, saw 6\\nSkipping line 1638: expected 2 fields, saw 3\\nSkipping line 1639: expected 2 fields, saw 3\\nSkipping line 1642: expected 2 fields, saw 3\\nSkipping line 1643: expected 2 fields, saw 3\\nSkipping line 1678: expected 2 fields, saw 3\\nSkipping line 1720: expected 2 fields, saw 3\\nSkipping line 1725: expected 2 fields, saw 9\\nSkipping line 1759: expected 2 fields, saw 4\\nSkipping line 1763: expected 2 fields, saw 3\\nSkipping line 1786: expected 2 fields, saw 4\\nSkipping line 1828: expected 2 fields, saw 3\\nSkipping line 1840: expected 2 fields, saw 4\\nSkipping line 1858: expected 2 fields, saw 6\\nSkipping line 1864: expected 2 fields, saw 14\\nSkipping line 1896: expected 2 fields, saw 4\\nSkipping line 1943: expected 2 fields, saw 7\\nSkipping line 1960: expected 2 fields, saw 3\\nSkipping line 2000: expected 2 fields, saw 3\\nSkipping line 2011: expected 2 fields, saw 6\\nSkipping line 2013: expected 2 fields, saw 3\\nSkipping line 2024: expected 2 fields, saw 3\\nSkipping line 2054: expected 2 fields, saw 3\\nSkipping line 2065: expected 2 fields, saw 3\\nSkipping line 2071: expected 2 fields, saw 6\\nSkipping line 2091: expected 2 fields, saw 6\\nSkipping line 2094: expected 2 fields, saw 3\\nSkipping line 2095: expected 2 fields, saw 3\\nSkipping line 2115: expected 2 fields, saw 3\\nSkipping line 2116: expected 2 fields, saw 5\\nSkipping line 2120: expected 2 fields, saw 3\\nSkipping line 2135: expected 2 fields, saw 4\\nSkipping line 2147: expected 2 fields, saw 5\\nSkipping line 2159: expected 2 fields, saw 7\\nSkipping line 2171: expected 2 fields, saw 7\\nSkipping line 2172: expected 2 fields, saw 3\\nSkipping line 2185: expected 2 fields, saw 4\\nSkipping line 2192: expected 2 fields, saw 4\\nSkipping line 2207: expected 2 fields, saw 3\\nSkipping line 2208: expected 2 fields, saw 3\\nSkipping line 2210: expected 2 fields, saw 7\\nSkipping line 2226: expected 2 fields, saw 3\\nSkipping line 2257: expected 2 fields, saw 4\\nSkipping line 2301: expected 2 fields, saw 4\\nSkipping line 2313: expected 2 fields, saw 3\\nSkipping line 2357: expected 2 fields, saw 3\\nSkipping line 2371: expected 2 fields, saw 4\\nSkipping line 2409: expected 2 fields, saw 7\\nSkipping line 2420: expected 2 fields, saw 4\\nSkipping line 2464: expected 2 fields, saw 3\\nSkipping line 2465: expected 2 fields, saw 3\\nSkipping line 2474: expected 2 fields, saw 3\\nSkipping line 2506: expected 2 fields, saw 3\\nSkipping line 2514: expected 2 fields, saw 4\\nSkipping line 2527: expected 2 fields, saw 6\\nSkipping line 2537: expected 2 fields, saw 3\\nSkipping line 2566: expected 2 fields, saw 5\\nSkipping line 2575: expected 2 fields, saw 4\\nSkipping line 2596: expected 2 fields, saw 4\\nSkipping line 2599: expected 2 fields, saw 4\\nSkipping line 2631: expected 2 fields, saw 3\\nSkipping line 2633: expected 2 fields, saw 3\\nSkipping line 2648: expected 2 fields, saw 3\\nSkipping line 2649: expected 2 fields, saw 3\\nSkipping line 2653: expected 2 fields, saw 3\\nSkipping line 2668: expected 2 fields, saw 5\\nSkipping line 2675: expected 2 fields, saw 3\\nSkipping line 2682: expected 2 fields, saw 7\\nSkipping line 2703: expected 2 fields, saw 3\\nSkipping line 2713: expected 2 fields, saw 3\\nSkipping line 2718: expected 2 fields, saw 3\\nSkipping line 2731: expected 2 fields, saw 3\\nSkipping line 2746: expected 2 fields, saw 3\\nSkipping line 2765: expected 2 fields, saw 6\\nSkipping line 2793: expected 2 fields, saw 3\\nSkipping line 2796: expected 2 fields, saw 4\\nSkipping line 2802: expected 2 fields, saw 3\\nSkipping line 2814: expected 2 fields, saw 6\\nSkipping line 2815: expected 2 fields, saw 3\\nSkipping line 2819: expected 2 fields, saw 4\\nSkipping line 2827: expected 2 fields, saw 3\\nSkipping line 2835: expected 2 fields, saw 3\\nSkipping line 2837: expected 2 fields, saw 3\\nSkipping line 2850: expected 2 fields, saw 7\\nSkipping line 2858: expected 2 fields, saw 8\\nSkipping line 2865: expected 2 fields, saw 9\\nSkipping line 2871: expected 2 fields, saw 3\\nSkipping line 2877: expected 2 fields, saw 3\\nSkipping line 2882: expected 2 fields, saw 3\\nSkipping line 2901: expected 2 fields, saw 3\\nSkipping line 2944: expected 2 fields, saw 3\\nSkipping line 2947: expected 2 fields, saw 3\\nSkipping line 2992: expected 2 fields, saw 5\\nSkipping line 3006: expected 2 fields, saw 3\\nSkipping line 3018: expected 2 fields, saw 9\\nSkipping line 3047: expected 2 fields, saw 3\\nSkipping line 3049: expected 2 fields, saw 3\\nSkipping line 3065: expected 2 fields, saw 3\\nSkipping line 3090: expected 2 fields, saw 4\\nSkipping line 3148: expected 2 fields, saw 3\\nSkipping line 3166: expected 2 fields, saw 4\\nSkipping line 3169: expected 2 fields, saw 3\\nSkipping line 3175: expected 2 fields, saw 3\\nSkipping line 3184: expected 2 fields, saw 3\\nSkipping line 3198: expected 2 fields, saw 3\\nSkipping line 3207: expected 2 fields, saw 3\\nSkipping line 3212: expected 2 fields, saw 4\\nSkipping line 3224: expected 2 fields, saw 3\\nSkipping line 3228: expected 2 fields, saw 5\\nSkipping line 3230: expected 2 fields, saw 4\\nSkipping line 3247: expected 2 fields, saw 3\\nSkipping line 3248: expected 2 fields, saw 3\\nSkipping line 3259: expected 2 fields, saw 3\\nSkipping line 3261: expected 2 fields, saw 3\\nSkipping line 3281: expected 2 fields, saw 7\\nSkipping line 3315: expected 2 fields, saw 4\\nSkipping line 3325: expected 2 fields, saw 4\\nSkipping line 3337: expected 2 fields, saw 3\\nSkipping line 3345: expected 2 fields, saw 3\\nSkipping line 3402: expected 2 fields, saw 3\\nSkipping line 3422: expected 2 fields, saw 3\\nSkipping line 3435: expected 2 fields, saw 3\\nSkipping line 3441: expected 2 fields, saw 4\\nSkipping line 3448: expected 2 fields, saw 3\\nSkipping line 3468: expected 2 fields, saw 3\\nSkipping line 3485: expected 2 fields, saw 3\\nSkipping line 3497: expected 2 fields, saw 4\\nSkipping line 3509: expected 2 fields, saw 3\\nSkipping line 3510: expected 2 fields, saw 4\\nSkipping line 3519: expected 2 fields, saw 3\\nSkipping line 3528: expected 2 fields, saw 4\\nSkipping line 3531: expected 2 fields, saw 4\\nSkipping line 3534: expected 2 fields, saw 3\\nSkipping line 3539: expected 2 fields, saw 3\\nSkipping line 3574: expected 2 fields, saw 3\\nSkipping line 3581: expected 2 fields, saw 3\\nSkipping line 3614: expected 2 fields, saw 3\\nSkipping line 3637: expected 2 fields, saw 3\\nSkipping line 3645: expected 2 fields, saw 3\\nSkipping line 3649: expected 2 fields, saw 3\\nSkipping line 3674: expected 2 fields, saw 3\\nSkipping line 3684: expected 2 fields, saw 4\\nSkipping line 3693: expected 2 fields, saw 3\\nSkipping line 3726: expected 2 fields, saw 3\\nSkipping line 3750: expected 2 fields, saw 5\\nSkipping line 3761: expected 2 fields, saw 3\\nSkipping line 3773: expected 2 fields, saw 4\\nSkipping line 3779: expected 2 fields, saw 4\\nSkipping line 3780: expected 2 fields, saw 3\\nSkipping line 3792: expected 2 fields, saw 3\\nSkipping line 3793: expected 2 fields, saw 4\\nSkipping line 3801: expected 2 fields, saw 3\\nSkipping line 3806: expected 2 fields, saw 4\\nSkipping line 3821: expected 2 fields, saw 3\\nSkipping line 3822: expected 2 fields, saw 3\\nSkipping line 3854: expected 2 fields, saw 3\\nSkipping line 3924: expected 2 fields, saw 4\\nSkipping line 3949: expected 2 fields, saw 3\\nSkipping line 3972: expected 2 fields, saw 3\\nSkipping line 3988: expected 2 fields, saw 6\\nSkipping line 4007: expected 2 fields, saw 3\\nSkipping line 4010: expected 2 fields, saw 3\\nSkipping line 4012: expected 2 fields, saw 4\\nSkipping line 4016: expected 2 fields, saw 3\\nSkipping line 4053: expected 2 fields, saw 3\\nSkipping line 4058: expected 2 fields, saw 3\\nSkipping line 4062: expected 2 fields, saw 3\\nSkipping line 4077: expected 2 fields, saw 4\\nSkipping line 4085: expected 2 fields, saw 3\\nSkipping line 4091: expected 2 fields, saw 3\\nSkipping line 4126: expected 2 fields, saw 3\\nSkipping line 4140: expected 2 fields, saw 4\\nSkipping line 4145: expected 2 fields, saw 4\\nSkipping line 4155: expected 2 fields, saw 7\\nSkipping line 4158: expected 2 fields, saw 3\\nSkipping line 4167: expected 2 fields, saw 3\\nSkipping line 4172: expected 2 fields, saw 4\\nSkipping line 4182: expected 2 fields, saw 3\\nSkipping line 4193: expected 2 fields, saw 6\\nSkipping line 4198: expected 2 fields, saw 3\\nSkipping line 4201: expected 2 fields, saw 4\\nSkipping line 4238: expected 2 fields, saw 3\\nSkipping line 4256: expected 2 fields, saw 3\\nSkipping line 4291: expected 2 fields, saw 4\\nSkipping line 4292: expected 2 fields, saw 3\\nSkipping line 4300: expected 2 fields, saw 7\\nSkipping line 4306: expected 2 fields, saw 3\\nSkipping line 4330: expected 2 fields, saw 4\\nSkipping line 4365: expected 2 fields, saw 3\\nSkipping line 4374: expected 2 fields, saw 5\\nSkipping line 4388: expected 2 fields, saw 3\\nSkipping line 4397: expected 2 fields, saw 3\\nSkipping line 4409: expected 2 fields, saw 3\\nSkipping line 4438: expected 2 fields, saw 3\\nSkipping line 4451: expected 2 fields, saw 3\\nSkipping line 4457: expected 2 fields, saw 3\\nSkipping line 4464: expected 2 fields, saw 3\\nSkipping line 4469: expected 2 fields, saw 4\\nSkipping line 4493: expected 2 fields, saw 6\\nSkipping line 4498: expected 2 fields, saw 3\\nSkipping line 4501: expected 2 fields, saw 3\\nSkipping line 4518: expected 2 fields, saw 4\\nSkipping line 4519: expected 2 fields, saw 6\\nSkipping line 4528: expected 2 fields, saw 3\\nSkipping line 4541: expected 2 fields, saw 3\\nSkipping line 4542: expected 2 fields, saw 4\\nSkipping line 4579: expected 2 fields, saw 3\\nSkipping line 4588: expected 2 fields, saw 4\\nSkipping line 4608: expected 2 fields, saw 3\\nSkipping line 4671: expected 2 fields, saw 6\\nSkipping line 4677: expected 2 fields, saw 3\\nSkipping line 4686: expected 2 fields, saw 5\\nSkipping line 4711: expected 2 fields, saw 3\\nSkipping line 4721: expected 2 fields, saw 3\\nSkipping line 4759: expected 2 fields, saw 3\\nSkipping line 4806: expected 2 fields, saw 3\\nSkipping line 4861: expected 2 fields, saw 3\\nSkipping line 4885: expected 2 fields, saw 3\\nSkipping line 4891: expected 2 fields, saw 8\\nSkipping line 4906: expected 2 fields, saw 9\\nSkipping line 4944: expected 2 fields, saw 3\\nSkipping line 4950: expected 2 fields, saw 3\\nSkipping line 4963: expected 2 fields, saw 5\\nSkipping line 5051: expected 2 fields, saw 5\\nSkipping line 5054: expected 2 fields, saw 3\\nSkipping line 5079: expected 2 fields, saw 3\\nSkipping line 5084: expected 2 fields, saw 3\\nSkipping line 5097: expected 2 fields, saw 3\\nSkipping line 5101: expected 2 fields, saw 3\\nSkipping line 5102: expected 2 fields, saw 3\\nSkipping line 5107: expected 2 fields, saw 4\\nSkipping line 5118: expected 2 fields, saw 3\\nSkipping line 5132: expected 2 fields, saw 5\\nSkipping line 5136: expected 2 fields, saw 3\\nSkipping line 5140: expected 2 fields, saw 7\\nSkipping line 5167: expected 2 fields, saw 4\\nSkipping line 5182: expected 2 fields, saw 4\\nSkipping line 5204: expected 2 fields, saw 7\\nSkipping line 5210: expected 2 fields, saw 3\\nSkipping line 5254: expected 2 fields, saw 4\\nSkipping line 5267: expected 2 fields, saw 3\\nSkipping line 5275: expected 2 fields, saw 3\\nSkipping line 5321: expected 2 fields, saw 3\\nSkipping line 5337: expected 2 fields, saw 5\\nSkipping line 5345: expected 2 fields, saw 3\\nSkipping line 5349: expected 2 fields, saw 3\\nSkipping line 5363: expected 2 fields, saw 4\\nSkipping line 5432: expected 2 fields, saw 3\\nSkipping line 5487: expected 2 fields, saw 3\\nSkipping line 5497: expected 2 fields, saw 4\\nSkipping line 5498: expected 2 fields, saw 3\\nSkipping line 5500: expected 2 fields, saw 3\\nSkipping line 5519: expected 2 fields, saw 5\\nSkipping line 5550: expected 2 fields, saw 3\\nSkipping line 5552: expected 2 fields, saw 6\\n'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ham\\tGo until jurong point</th>\n",
              "      <th>crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham\\tOk lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam\\tFree entry in 2 a wkly comp to win FA Cu...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham\\tU dun say so early hor... U c already the...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham\\tNah I don't think he goes to usf</td>\n",
              "      <td>he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam\\tFreeMsg Hey there darling it's been 3 we...</td>\n",
              "      <td>£1.50 to rcv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          ham\\tGo until jurong point  crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
              "0                 ham\\tOk lar... Joking wif u oni...                                                NaN                                       \n",
              "1  spam\\tFree entry in 2 a wkly comp to win FA Cu...                                                NaN                                       \n",
              "2  ham\\tU dun say so early hor... U c already the...                                                NaN                                       \n",
              "3              ham\\tNah I don't think he goes to usf                        he lives around here though                                       \n",
              "4  spam\\tFreeMsg Hey there darling it's been 3 we...                                       £1.50 to rcv                                       "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxW80SGJcwPP"
      },
      "source": [
        "# Importing our library\n",
        "# ---\n",
        "#\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF7rixbGclp_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ddc16e6e-5473-48b9-954c-5841e81b10b8"
      },
      "source": [
        "# Loading our uploaded Data\n",
        "# ---\n",
        "# We define a separator (in this case, a tab) and rename the columns accordingly\n",
        "# \n",
        "df = pd.read_csv('/content/SMSSpamCollection.txt', sep='\\t', header=None, names=['label', 'message'], encoding='latin-1')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgQU75Rhc2i2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "379b717e-bab2-4c2b-fb84-e645a44b38da"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 1. Converting the labels from strings to binary values for our classifier\n",
        "# \n",
        "df['label'] = df.label.map({'ham': 0, 'spam': 1})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXLkppitgQ7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e038d276-f156-4bdd-fe70-d03732be74d0"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 2. Converting all characters in the message to lower case:\n",
        "# \n",
        "df['message'] = df.message.map(lambda x: x.lower())\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point, crazy.. available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar... joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so early hor... u c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point, crazy.. available only ...\n",
              "1      0                      ok lar... joking wif u oni...\n",
              "2      1  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      0  u dun say so early hor... u c already then say...\n",
              "4      0  nah i don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG3j0ymwgWOx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "feac1058-7fd4-4ffa-c61e-620f63692ca2"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 3. Remove any punctuation:\n",
        "# \n",
        "df['message'] = df.message.str.replace('[^\\w\\s]', '')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point crazy available only in ...\n",
              "1      0                            ok lar joking wif u oni\n",
              "2      1  free entry in 2 a wkly comp to win fa cup fina...\n",
              "3      0        u dun say so early hor u c already then say\n",
              "4      0  nah i dont think he goes to usf he lives aroun..."
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0B-lfLPgivV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce234d2-93a5-4020-b622-bf709de54f62"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 4. tokenize the messages into into single words using nltk. \n",
        "# First, we have to import and download the tokenizer from the console:\n",
        "# \n",
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ttknwa9guS4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a057dfe0-6952-4bb1-8193-4fe2352dc24c"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 5. Applying the tokenization. \n",
        "# What is tokenization (http://bit.ly/WhatisTokenization)\n",
        "# \n",
        "df['message'] = df['message'].apply(nltk.word_tokenize)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  [go, until, jurong, point, crazy, available, o...\n",
              "1      0                     [ok, lar, joking, wif, u, oni]\n",
              "2      1  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
              "3      0  [u, dun, say, so, early, hor, u, c, already, t...\n",
              "4      0  [nah, i, dont, think, he, goes, to, usf, he, l..."
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kWxzerKg0V6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "151a3749-3fda-48c5-abfa-4302c1e9b3d4"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 6. We then perform some word stemming. \n",
        "# The idea of stemming is to normalize our text for all variations of words carry the same meaning, \n",
        "# regardless of the tense. One of the most popular stemming algorithms is the Porter Stemmer:\n",
        "# \n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        " \n",
        "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[go, until, jurong, point, crazi, avail, onli,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[free, entri, in, 2, a, wkli, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[u, dun, say, so, earli, hor, u, c, alreadi, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[nah, i, dont, think, he, goe, to, usf, he, li...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  [go, until, jurong, point, crazi, avail, onli,...\n",
              "1      0                       [ok, lar, joke, wif, u, oni]\n",
              "2      1  [free, entri, in, 2, a, wkli, comp, to, win, f...\n",
              "3      0  [u, dun, say, so, earli, hor, u, c, alreadi, t...\n",
              "4      0  [nah, i, dont, think, he, goe, to, usf, he, li..."
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXv3cwwrhAWw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6e947021-2d95-4cb8-ddd0-ea7abb88dc27"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 7. We will transform the data into occurrences, \n",
        "# which will be the features that we will feed into our model:\n",
        "#\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# This converts the list of words into space-separated strings\n",
        "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "counts = count_vect.fit_transform(df['message'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so earli hor u c alreadi then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i dont think he goe to usf he live around ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point crazi avail onli in bugi...\n",
              "1      0                              ok lar joke wif u oni\n",
              "2      1  free entri in 2 a wkli comp to win fa cup fina...\n",
              "3      0        u dun say so earli hor u c alreadi then say\n",
              "4      0  nah i dont think he goe to usf he live around ..."
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VERkaCMThK8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "23955c95-a905-46c0-f889-5df93a1267b4"
      },
      "source": [
        "# Pre-processing\n",
        "# ---\n",
        "# 8. We could leave it as the simple word-count per message, \n",
        "# but it is better to use Term Frequency Inverse Document Frequency, more known as tf-idf:\n",
        "#\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "transformer = TfidfTransformer().fit(counts)\n",
        "\n",
        "counts = transformer.transform(counts)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go until jurong point crazi avail onli in bugi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entri in 2 a wkli comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say so earli hor u c alreadi then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah i dont think he goe to usf he live around ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0      0  go until jurong point crazi avail onli in bugi...\n",
              "1      0                              ok lar joke wif u oni\n",
              "2      1  free entri in 2 a wkli comp to win fa cup fina...\n",
              "3      0        u dun say so earli hor u c alreadi then say\n",
              "4      0  nah i dont think he goe to usf he live around ..."
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vksf5PobhVQ-"
      },
      "source": [
        "# Training the Model\n",
        "# ---\n",
        "# Now that we have performed feature extraction from our data, \n",
        "# it is time to build our model. We will start by splitting our data into training and test sets:\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUWlrPzwhfAb"
      },
      "source": [
        "# Training the Model\n",
        "# ---\n",
        "# Then, all that we have to do is initialize the Naive Bayes Classifier and fit the data. \n",
        "# For text classification problems, the Multinomial Naive Bayes Classifier is well-suited:\n",
        "# \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB().fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT0zZNSkhpvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8606c0d-13cf-416b-f381-c0b5322958cf"
      },
      "source": [
        "# Evaluating the Model\n",
        "# ---\n",
        "# Once we have put together our classifier, we can evaluate its performance in the testing set:\n",
        "#\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "print(np.mean(predicted == y_test))\n",
        "\n",
        "# Our simple Naive Bayes Classifier has 94.8% accuracy with this specific test set!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9480286738351255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lgaf8JCiI-L"
      },
      "source": [
        "## <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG5nw1kRtU0g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "306a0cf8-2eb5-40d6-cdf5-8865160cbf88"
      },
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# In this challenge, we have been tasked with creating a classifier, the training set,\n",
        "# then training the classifier using the training set and making a prediction.\n",
        "# ---\n",
        "# The training set (X) consits of length, weight and shoe size. \n",
        "# Y contains the associated labels (male or female).\n",
        "# \n",
        "\n",
        "X1= [[121, 80, 44], [180, 70, 43], [166, 60, 38], [153, 54, 37], [166, 65, 40], [190, 90, 47], [175, 64, 39],\n",
        "     [174, 71, 40], [159, 52, 37], [171, 76, 42], [183, 85, 43]]\n",
        "\n",
        "Y = ['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male']\n",
        "\n",
        "# Training the classifier:\n",
        "#\n",
        "df_shoe=pd.DataFrame(X1,columns=['Length','Weight','Shoe_size'])\n",
        "df_shoe\n",
        "\n",
        "\n",
        "# Making the prediciton:\n",
        "# Using the GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \n",
        "# \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Shoe_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>121</td>\n",
              "      <td>80</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>180</td>\n",
              "      <td>70</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>166</td>\n",
              "      <td>60</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>153</td>\n",
              "      <td>54</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>65</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>190</td>\n",
              "      <td>90</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>175</td>\n",
              "      <td>64</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>174</td>\n",
              "      <td>71</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>159</td>\n",
              "      <td>52</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>171</td>\n",
              "      <td>76</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>183</td>\n",
              "      <td>85</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Length  Weight  Shoe_size\n",
              "0      121      80         44\n",
              "1      180      70         43\n",
              "2      166      60         38\n",
              "3      153      54         37\n",
              "4      166      65         40\n",
              "5      190      90         47\n",
              "6      175      64         39\n",
              "7      174      71         40\n",
              "8      159      52         37\n",
              "9      171      76         42\n",
              "10     183      85         43"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I75g3-Sfalnu"
      },
      "source": [
        "# converting to series\n",
        "Y=pd.Series(Y)\n",
        "Y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dl8bgkDhTzj"
      },
      "source": [
        "# Using the GaussianNB classifier (i.e.\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clc=GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4PWygaKhT_l",
        "outputId": "ede18016-79e6-49fa-88bb-51133ed402ba"
      },
      "source": [
        "#train classifier\n",
        "clc.fit(df_shoe,Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XvBBkzfhUIR",
        "outputId": "ecbfcfc9-d7d3-4898-a13c-610666984b38"
      },
      "source": [
        "#Prediction\n",
        "prediction=clc.predict(X)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['male', 'male', 'female', 'female', 'female', 'male', 'female',\n",
              "       'female', 'female', 'male', 'male'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya2rrco1udt2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_o1y0AOijK2"
      },
      "source": [
        "gender=np.array(['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female', 'female', 'male', 'male'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "Ydv9j6gTijAK",
        "outputId": "181f5fd7-aa01-40cf-9e8f-325928b83d1d"
      },
      "source": [
        "#checking prediction if same with initial label\n",
        "\n",
        "assert prediction.all() == gender"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-16278c40e8cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#checking prediction if same with initial label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbil0bxWkjvL",
        "outputId": "72112244-d97a-4912-9206-4e61d5391814"
      },
      "source": [
        "Y.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['male', 'male', 'female', 'female', 'male', 'male', 'female',\n",
              "       'female', 'female', 'male', 'male'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftPs87DYk5iN",
        "outputId": "56b37b76-5d5a-4114-bb86-023cd526c811"
      },
      "source": [
        "type(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dks7-j1Kk5en",
        "outputId": "b1905c89-bf9e-4909-ebf5-7d1b047c7b2e"
      },
      "source": [
        "type(gender)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeEZPsxjkjrA",
        "outputId": "3875ecc8-b447-4fb7-ae50-6e970beaa8ed"
      },
      "source": [
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L9NLAFHhUWh",
        "outputId": "a4849829-035b-41f3-bc59-3daf205cebde"
      },
      "source": [
        "gender.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11,)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfg92ijWmC1W",
        "outputId": "ec0a359c-c7a2-4ac0-8139-5ebb9e824de4"
      },
      "source": [
        "list(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male',\n",
              " 'male',\n",
              " 'female',\n",
              " 'female',\n",
              " 'female',\n",
              " 'male',\n",
              " 'female',\n",
              " 'female',\n",
              " 'female',\n",
              " 'male',\n",
              " 'male']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbcvwQasmC5D",
        "outputId": "dd3f7393-4646-4814-9e2c-a5ff878d31c6"
      },
      "source": [
        "list(gender)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male',\n",
              " 'male',\n",
              " 'female',\n",
              " 'female',\n",
              " 'male',\n",
              " 'male',\n",
              " 'female',\n",
              " 'female',\n",
              " 'female',\n",
              " 'male',\n",
              " 'male']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "EpVdR4-umC9b",
        "outputId": "f7ef2a1c-5c8e-4936-e64a-b6b99f864ed4"
      },
      "source": [
        "assert list (prediction) == list (gender)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-9bab9491d66a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWeGKsSTmvRZ"
      },
      "source": [
        "=GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHn_lBT8iPVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0ecd5167-fb1e-46e2-8da6-4fad9a1d0b44"
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Question: Use the titanic disaster dataset to create a Gaussian Naive Bayes classifier model \n",
        "# (i.e. from sklearn.naive_bayes import GaussianNB) that will make a prediction of survival \n",
        "# using passenger ticket fare information. \n",
        "# ---\n",
        "# Dataset url: http://bit.ly/TitanicDataset \n",
        "# \n",
        "train=pd.read_csv('/content/train.csv')\n",
        "train.head(5)\n",
        "\n",
        "test=pd.read_csv('/content/test.csv')\n",
        "test.head(5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXrMWTwEras5"
      },
      "source": [
        "X = train.Fare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s9m44jcra6S"
      },
      "source": [
        "Y=train.Survived"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUFtyRFgrbDX",
        "outputId": "fca958fc-e42f-40ca-9d09-2564cdbd6992"
      },
      "source": [
        "X.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efa4Q6bSrbV4",
        "outputId": "8e62d7b7-f3aa-48c8-dd49-c9f24ff1331b"
      },
      "source": [
        "X.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEQQilKMr276"
      },
      "source": [
        "clc2=GaussianNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxKGBOjxr2xw",
        "outputId": "425ba964-9ca9-47d8-c083-9446df0a6ec7"
      },
      "source": [
        "#fitting models\n",
        "clc2.fit(X.values.reshape(-1, 1),Y.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Q-3SYJsgeZ",
        "outputId": "97ab1f7a-45b8-4700-c6af-ab326f58beb3"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891,)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHLVzMeysgGt",
        "outputId": "01d2f49f-01b9-4979-a53b-a4a13dbae5ef"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891,)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBCbNxMmulHZ"
      },
      "source": [
        "#Prediction\n",
        "prediction=clc.predict(X)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgYYPPmdulVh"
      },
      "source": [
        "X_test=test.Fare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiJC91KWvKg0",
        "outputId": "30177ae1-ff5b-4560-978f-6cff83c34e4e"
      },
      "source": [
        "X_test.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF6G5bivvKcy"
      },
      "source": [
        "meantest=X_test.mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_j7-f8-vKQT"
      },
      "source": [
        "X_test.fillna(meantest,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXdJsTRgvKHx"
      },
      "source": [
        "predicted=clc2.predict(X_test.values.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfUGtpsbwpLv",
        "outputId": "a5dc25a6-7d90-43dd-b32b-b2bcb60f9d4b"
      },
      "source": [
        "predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZizDQj7iQ4O"
      },
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# Question: Create a GaussianNB classifier (i.e. from sklearn.naive_bayes import GaussianNB) \n",
        "# to identify the different species of iris flowers.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/MSIrisDatasetNB\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}